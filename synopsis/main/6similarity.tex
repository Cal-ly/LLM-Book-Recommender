\chapter{Vector Similarity Search with FAISS}
\label{chapter:faiss}

Once books and queries are embedded into the same semantic space, the system must identify the most relevant books for a given user input. This is achieved using vector similarity search. In this project, the FAISS (Facebook AI Similarity Search) library \parencite{faiss} is used to enable fast and accurate nearest-neighbor retrieval over the 5,160 book vectors.

\section{Similarity Search Theory}
\label{sec:similarity-theory}

Let \( \vec{q} \in \mathbb{R}^{384} \) represent the embedded user query, and let \( \{\vec{b}_1, \vec{b}_2, \dots, \vec{b}_n\} \) denote the embedded book vectors. The similarity between the query and each book is computed using squared L2 (Euclidean) distance:

\begin{equation}
    \text{dist}(\vec{q}, \vec{b}_i) = \|\vec{q} - \vec{b}_i\|_2^2
\end{equation}

The top \( k \) nearest neighbors (i.e., those with the smallest distances) are returned as recommended books. This approach assumes that semantically similar texts lie close together in vector space.

\section{Why FAISS?}
\label{sec:faiss-choice}

FAISS is optimized for fast similarity search over high-dimensional vectors. It was selected for this project because it:

\begin{itemize}
    \item \textbf{Performs well on CPU} — fast enough for real-time use
    \item \textbf{Supports exact and approximate search} — adaptable for scale
    \item \textbf{Offers simple integration with NumPy and PyTorch}
    \item \textbf{Runs offline} — no internet connection required
\end{itemize}

This implementation uses \texttt{IndexFlatL2}, a brute-force index that performs exact nearest-neighbor search using squared L2 distance. It is suitable for small to medium datasets and does not require tuning.

\section{Implementation}
\label{sec:similarity-implementation}

After the embeddings were generated (see Chapter~\ref{chapter:embedding}), the similarity search process was implemented as follows:

\begin{enumerate}
    \item Initialize a \texttt{faiss.IndexFlatL2} index with vector dimension 384.
    \item Add the 5,160 book vectors to the index.
    \item At runtime:
    \begin{itemize}
        \item Embed the user query using the same MiniLM model.
        \item Use FAISS to find the top \( k \) nearest book vectors.
        \item Retrieve metadata from \texttt{books\_indexed\_with\_embeddings.csv}.
    \end{itemize}
\end{enumerate}

The system achieves sub-second response times on consumer-grade laptops using only CPU.

\section{Summary}
\label{sec:similarity-summary}

FAISS powers the core similarity engine of the recommender system. Combined with MiniLM embeddings, it enables local, real-time, and semantically aware recommendations. The entire matching process relies solely on content, requiring no user profiles or interaction history.
