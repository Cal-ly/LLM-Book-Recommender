\chapter{Introduction}
\label{chapter:introduction}

\section{Motivation}
\label{sec:motivation}

This project explores the feasibility of deploying local machine learning models for intelligent information retrieval in local environments. 
As a case study, a fully local book recommendation system is developed. 
It leverages Natural Language Processing (NLP) techniques to analyze both book descriptions and natural language queries from users, enabling semantically meaningful, content-based recommendations.

In contrast to cloud-based systems that depend on centralized APIs and remote computation, this solution demonstrates a standalone, offline setup. 
All data processing — including text embedding, category inference, indexing, and query resolution — occurs on the user’s device, ensuring that no personal data leaves the local environment.

The core goal is to evaluate whether lightweight transformer-based models, specifically sentence transformers like MiniLM, can provide reliable and personalized recommendations within such constraints. 
The system incorporates semantic embedding, category inference through zero-shot classification, vector similarity search via FAISS, and Streamlit interface. 
These components collectively address the broader question of how accessible and effective locally hosted AI tools can be for individual users.

\section{Problem Definition}
\label{sec:problem-definition}

The project is centered around the following research question:

\begin{quote}
\textit{How can a local ML model be used to recommend books based on natural language descriptions, relying only on locally running models?}
\end{quote}

This leads to three guiding sub-questions:

\begin{enumerate}
    \item \label{itm:subq-embedding} \textit{What techniques exist for embedding text into meaningful vectors?}
    \item \label{itm:subq-similarity} \textit{How can vector similarity be used for finding relevant books?}
    \item \label{itm:subq-classification} \textit{How can genre categories be inferred and used to improve indexing and filtering?}
    \item \label{itm:subq-limitations} \textit{What are the practical limitations of a local, content-only recommendation system?}
\end{enumerate}

These sub-questions form the conceptual framework for the analysis presented throughout the synopsis.

\section{Link to code repository}
The code is public on GitHub: \href{https://github.com/Cal-ly/LLM-Book-Recommender}{\textit{https://github.com/Cal-ly/LLM-Book-Recommender}}.
